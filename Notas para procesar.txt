
*Preguntarle a Fabián sobre algún proyecto paralelizable para CUDA. ¿Quizás replicar algún paper con dependencia espacial?

Mandarle un mail a Pablo Cornaglia diciendole que queremos estar en FISCOM

Hay que trabajar con una versión vieja de CUDA en el cluster

Para verificar los drivers y las características de la placa sin necesidad de usar CUDA
nvidia-msi

MakeFile tutorial
https://makefiletutorial.com/#getting-started

En el código multmal_solucion se resuelve la cuenta usando una librería de CUDA
Le podemos decir cuántas GPUs usar

Dependiendo de la función que usemos nos va a pedir que las matrices estén cargadas en CPU o GPU

ifdef significa que voy a compilar con opciones. Si defino un macro SIMPLECPU se va a compilar esa parte. De esta forma puedo tener muchos programas en un único programa
Luego para correr cada parte hay que compilar con esas opciones ej: nvcc ... -SIMPLECPU -o ...


COPIAR LOS GOOGLE COLABS DE LA MATERIA


No hay que optimizar prematuramente. Podemos terminar con un código re optimizado de cosas que no eran necesario optimizar


Profiling en python
Podría agregar relojes manuales antes y después de cada función. O podría usar librerías que se encargan de hacer todo por mi. Le pregunté a ChatPGT y me comentó sobre las librerías cProfile y profile. Además, hay herramientas de visualización del profiling mejor interpretables que el texto completo.

ME QUEDARON DUDAS DE LA CLASE 5. ESTÁN EN EL POWER POINT

Intentar optimizar mi código de Python usando Numba

Actividades:
*Decargar todos los google colabs
*Pasar comentarios a pdf clase 7
*Comitear el github
*Pasar preguntas ANKI
*Hacer preguntas ANKI de las primeras clases


Dentro de los kernels en Numba no se puede meter cualquier cosa porque corre en el device. Entonces no puedo pedir desde el kernel acceder a numpy porque no está en la GPU






Instrucciones del uso del cluster


Para compilar
nvcc archivo.cu -o nombre_ejecutable

Para ejecutar
./nombre_ejecutable

Para hacer un JobGPU
1ro estructura con prefijo de línea #$ que da directivas al cluster qué hacer
2do ejecutar lo mismo que en la cmd: ./multmat
3ro puedo decir que los datos los mande a un .dat usando "done < tiempos.dat" luego de un ;

Tmb se puede configurar un jobGPU genérico que incluya solo el 1er paso y en el segundo paso poner solo la línea
$1
que tomará input del usuario en la cmd. Este tipo de jobs se ejecutan de la forma
qsub jobGPU ./name_ejecutable
habiendo antes compilado el .cu

Me puede llegar a dar error si no tengo los módulos correctos instalados. Para cargar un módulo:
module load name_modulo
Para ver qué módulos hay disponibles
module unload name_modulo
Para eliminar un módulo
module unload name_modulo

A veces voy a tener errores como
*warnings asociadas a Thrust
La solución en estos casos suele ser usar la versión más vieja del mdoulo de cuda existente en el cluster

Hay ocasiones donde tendré que indicarle al compilador que se linkee con una librería particular, por ejemplo si uso cublas, cusparse o cufft. En tal caso hay que añadir la instrucción
-lname_library
en la etapa de compilación (nvcc)

qstat, qdel

Admin: Gustavo Berman
soporte.fisica@cab.cnea.gov.ar

man bash_command
ejemplo
man qstat
PROBAR


Usar make para compilar. Dentro creo que tiene las instrucciones extras que se le pasan al compilador para que corra sin problemas


Duda CUDA: Preguntar por qué no puedo correr mi código
