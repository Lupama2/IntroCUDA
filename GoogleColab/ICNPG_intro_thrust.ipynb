{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "g6HXDOSw3hc-",
        "outputId": "c7c5e237-e9ee-4dee-98bd-ba9c6caecc48"
      },
      "source": [
        "%%html\n",
        "<marquee style='width: 100%; color: blue;'><b>ICNPG2023 en Google Colaboratory-Instituto Balseiro</b></marquee>\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<marquee style='width: 100%; color: blue;'><b>ICNPG2023 en Google Colaboratory-Instituto Balseiro</b></marquee>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH1rrvSR7z7t"
      },
      "source": [
        "# Preparativos para programar CUDA C/C++ en google colabs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8w8rRnK_fDB"
      },
      "source": [
        "Hola!, Bueno, aqui va un ejemplito de como correr codigo CUDA C/C++ en colabs\n",
        "[[1]](https://https://www.wikihow.com/Run-CUDA-C-or-C%2B%2B-on-Jupyter-(Google-Colab)\n",
        "[[2]](https://stackoverflow.com/questions/56854243/how-to-link-the-libraries-when-executing-cuda-program-on-google-colab).\n",
        "\n",
        "No se olviden de Runtime-> Change Runtime Type -> GPU. Para que funque a cada linea la tienen que ejecutar con un Shift-Enter o Ctrl-Enter o el botoncito de play."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snj3bwGx_z-c"
      },
      "source": [
        "miremos que version de nvcc tenemos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzIRSGebudXT",
        "outputId": "6514f74e-1b51-4401-bf1b-8fd919cd4f12"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjdc7qaxACgq"
      },
      "source": [
        "A ver que placa nos toco..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAOT_KANAFS6",
        "outputId": "13c3dc26-d477-4886-f385-52b2999022a9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 27 20:02:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI2A2Sz0ARXc"
      },
      "source": [
        "lindas GPUs!!. Ahora, para poder correr Cuda C/C++ instalamos un plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A70Y4gWoeqZY"
      },
      "source": [
        "Veamos que cpu tenemos..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnc5urx76x9H",
        "outputId": "c6307c64-17c9-4e58-ad1d-114bb869781f"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tiene dos procesadores, entonces no va a ser muy provechoso paralelizar en cpu..."
      ],
      "metadata": {
        "id": "FbB2PyXPU1c8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04ZpNeYqevV1"
      },
      "source": [
        "Como vamos a programar en cuda C/C++ nos va a venir buen instalar un plugin, asi corremos sin compilar explicitamente, como si fuera python :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qustrOFnAZV8",
        "outputId": "a04bd0ed-844a-4903-ddb2-3b6e7de9f1b1"
      },
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter to /tmp/pip-req-build-mtuc9_od\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter /tmp/pip-req-build-mtuc9_od\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=07fc14b85531ccccd560004c939ced8e8e71587c75a71920608c576f18c3111f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jmedw85k/wheels/65/6f/8e/80e37ad4f364ae56c9806a68974265420b0d623cc5434935d5\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FT5VL6VAh0U"
      },
      "source": [
        "y luego cargarlo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKpaprRBvkc3",
        "outputId": "20fdf9ef-30ef-4c01-b0a9-bf5e0d1c8e4c"
      },
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKtj2kNVLTcg"
      },
      "source": [
        "Listo!, con eso ya podemos correr codigo CUDA C/C++ en el notebook Jupyter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO4n1xfLK9oO"
      },
      "source": [
        "Para terminar, es conveniente montar nuestro google drive, asi podemos acceder a nuestros archivos, que pueden ser headers, etc. Nos va a pedir un permiso y un codigo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNc_gJpPLCiT",
        "outputId": "2a3c9165-c24d-4bb3-8ef5-2fe4350d9e10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3nbamuGAary"
      },
      "source": [
        "# Suma de vectores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g9KJ-pePwK6"
      },
      "source": [
        "Solucion con bibliotecas. Para que ande hay que hacerlo en dos partes. Primero generar el codigo en una carpeta local del server:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BiobhEHPy4h",
        "outputId": "93ac9542-f306-45fa-ef92-f07ad3b75193"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "using namespace thrust::placeholders;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4), y(4);\n",
        "\n",
        "  // Esto seria ilegal si x e y fueran simples punteros a memoria de device!  \n",
        "  x[0] = 1;\n",
        "  x[1] = 2;\n",
        "  x[2] = 3;\n",
        "  x[3] = 4;\n",
        "\n",
        "  y[0] = 4;\n",
        "  y[1] = 3;\n",
        "  y[2] = 2;\n",
        "  y[3] = 1;\n",
        "\n",
        "  // algoritmos de thrust: toman rangos de uno o mas vectores y una operacion \n",
        "\n",
        "  thrust::transform(x.begin(), x.end(), y.begin(), y.begin(),\n",
        "    _1 + _2\n",
        "  );\n",
        "\n",
        "  // y es ahora {5, 5, 5, 5} --> HANDS-ON: comprobar!\n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << y[i] << std::endl; //o usar printf...\n",
        "\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmSi4EKDreYj"
      },
      "source": [
        "# SAXPY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reFdGdGqJCxk",
        "outputId": "57c4c2e2-a537-4808-a9b8-1ff4074073a6"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "using namespace thrust::placeholders;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4), y(4);\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 6;\n",
        "  x[3] = 8;\n",
        "\n",
        "  y[0] = 4;\n",
        "  y[1] = 3;\n",
        "  y[2] = 2;\n",
        "  y[3] = 1;\n",
        "  float a=0.5;\n",
        "\n",
        "  thrust::transform(x.begin(), x.end(), y.begin(), y.begin(),\n",
        "    a*_1 + _2\n",
        "  );\n",
        "  // y es ahora {5, 5, 5, 5} --> HANDS-ON: comprobar!\n",
        "  for(int i=0;i<4;i++)\n",
        "  printf(\"%f\\n\", float(y[i]));\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.000000\n",
            "5.000000\n",
            "5.000000\n",
            "5.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvLlxFh7pZz"
      },
      "source": [
        "# Transformación arbitraria de dos arrays\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPaXhDUEA9uS",
        "outputId": "ad4f6988-87fa-4fcc-adf8-dc14cd2ce411"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "\n",
        "struct mi_operacion\n",
        "{\n",
        "          __device__\n",
        "          float operator()(float a, float b)\n",
        "          {\n",
        "                  return sqrt(a+b);\n",
        "          }\n",
        "};\n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4), y(4);\n",
        "  x[0] = 1;\n",
        "  x[1] = 2;\n",
        "  x[2] = 3;\n",
        "  x[3] = 4;\n",
        "\n",
        "  y[0] = 4;\n",
        "  y[1] = 3;\n",
        "  y[2] = 2;\n",
        "  y[3] = 1;\n",
        "\n",
        "  thrust::transform(x.begin(), x.end(), y.begin(), y.begin(),mi_operacion());\n",
        "\n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << y[i] << std::endl;\n",
        "  \n",
        "  std::cout << \"sqrt(5)=\" << sqrt(5.0) << std::endl;\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.23607\n",
            "2.23607\n",
            "2.23607\n",
            "2.23607\n",
            "sqrt(5)=2.23607\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "en esta caso no vamos a usar %%cu porque necesitamos compilar con algunas opciones (y no sabria como agregarlas en el plugin ese)"
      ],
      "metadata": {
        "id": "XQG7AZ4xUEzx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EsbrPxOjsWD1",
        "outputId": "02b0fe31-ef2d-4167-b411-71d390926fdc"
      },
      "source": [
        "%%cuda --name lambdas.cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "\n",
        "struct mi_operacion\n",
        "{\n",
        "          __device__\n",
        "          float operator()(float a, float b)\n",
        "          {\n",
        "                  return sqrt(a+b);\n",
        "          }\n",
        "};\n",
        "\n",
        "int main()\n",
        "{\n",
        "    thrust::device_vector<float> x(4), y(4);\n",
        "    x[0] = 1;\n",
        "    x[1] = 2;\n",
        "    x[2] = 3;\n",
        "    x[3] = 4;\n",
        "\n",
        "    y[0] = 4;\n",
        "    y[1] = 3;\n",
        "    y[2] = 2;\n",
        "    y[3] = 1;\n",
        "\n",
        "    thrust::transform(x.begin(), x.end(), y.begin(), y.begin(),\n",
        "        [=] __device__ (float x1,float x2) \n",
        "        {\n",
        "            return sqrt(x1 + x2);\n",
        "        }\n",
        "    );\n",
        "  \n",
        "    for(int i=0;i<4;i++)\n",
        "    std::cout << y[i] << std::endl;\n",
        "\n",
        "    std::cout << \"sqrt(5)=\" << sqrt(5.0) << std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/lambdas.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l19MbidMsl3W"
      },
      "source": [
        "!nvcc -O2 --extended-lambda /content/src/lambdas.cu -o lambdas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxp1Xtf2sYZj",
        "outputId": "7207d294-3a50-468a-cf3b-8fabf1569b94"
      },
      "source": [
        "!/content/lambdas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.23607\n",
            "2.23607\n",
            "2.23607\n",
            "2.23607\n",
            "sqrt(5)=2.23607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruaow9GRtSXh"
      },
      "source": [
        "# Normalización de un vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRwcW9WetdIh",
        "outputId": "d1571703-d632-4049-dfd1-6ca8c5dd955d"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <iostream>\n",
        "\n",
        "struct mi_operacion // normaliza por N\n",
        "{\n",
        "      public:\n",
        "      float Norm;\n",
        "      mi_operacion(float suma){Norm=suma;};\n",
        "          __device__\n",
        "          float operator()(float a)\n",
        "          {\n",
        "                  return a/Norm;\n",
        "          }\n",
        "};\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4), y(4);\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  float suma = thrust::reduce(x.begin(), x.end());\n",
        "  thrust::transform(x.begin(), x.end(), x.begin(),mi_operacion(suma));\n",
        "  // HANDS-ON: chequear que este normalizado...\n",
        "\n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << x[i] << std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n",
            "0.4\n",
            "0.3\n",
            "0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8nFWyzSt8EL"
      },
      "source": [
        "ahora probemos simplificar un poco la syntaxis, reemplazando el functor por placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBal-L1VtlAG",
        "outputId": "58404539-e23f-463c-cd38-43d5a1f64cb2"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "\n",
        "using namespace thrust::placeholders;\n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4);\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  float suma = thrust::reduce(x.begin(), x.end());\n",
        "  thrust::transform(x.begin(), x.end(), x.begin(),_1/suma);\n",
        "  // HANDS-ON: chequear que este normalizado...\n",
        "\n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << x[i] << std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n",
            "0.4\n",
            "0.3\n",
            "0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Tw6XMsuYq_"
      },
      "source": [
        "Veamos ahora como se puede interoperar entre CUDA C/C++ y Thrust. Usamos thrust para manejar alocacion y copias de arrays en device pero el resto lo hacemos con cuda kernels y punteros crudos a memoria de device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAAKAEI9t5Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e05448e-5579-4053-c2fa-9da8b413bcca"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "\n",
        "__global__ \n",
        "void kernel_normaliza(float *x, float suma, int dim)\n",
        "{\n",
        "    int id = threadIdx.x + (blockIdx.x * blockDim.x); \n",
        "    if (id < dim)\n",
        "    {\n",
        "         x[id] = x[id]/suma;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4);\n",
        "\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  float suma = thrust::reduce(x.begin(), x.end());\n",
        "\n",
        "  float * x_ptr = thrust::raw_pointer_cast(&x[0]);\n",
        "\n",
        "  kernel_normaliza<<<1,4>>>(x_ptr,suma,4); \n",
        "  // HANDS-ON: chequear que este normalizado...\n",
        "\n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << x[i] << std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n",
            "0.4\n",
            "0.3\n",
            "0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJpHRKU7u54u"
      },
      "source": [
        "Ahora probemos al reves, la alocacion y copias las hacemos con CUDA, y al kernel lo reemplazamos por un algoritmo de thrust"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_p3DWMDvBjb",
        "outputId": "9fb617d6-e8fe-4552-e639-e301706ae312"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_ptr.h>\n",
        "#include <thrust/device_free.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/reduce.h>\n",
        "\n",
        "using namespace thrust::placeholders;\n",
        "int main(void)\n",
        "{\n",
        "  float *raw_ptr;\n",
        "  cudaMalloc((void **)&raw_ptr, 4*sizeof(float));\n",
        "  thrust::device_ptr<float> x(raw_ptr);\n",
        "\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  float suma = thrust::reduce(x, x+4);\n",
        "  thrust::transform(x,x+4,x,_1/suma);\n",
        "\n",
        "  for(int i=0;i<4;i++) std::cout << x[i] << std::endl;\n",
        "\n",
        "  thrust::device_free(x);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2\n",
            "0.4\n",
            "0.3\n",
            "0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTeqjW-QwaYr"
      },
      "source": [
        "Normalicemos ahora no por la suma, pero por la norma euclidea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OtIH239uUmv",
        "outputId": "93b36e4b-7a68-4ec8-f6e1-5d9b727aba23"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/transform_reduce.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <cmath>\n",
        "\n",
        "struct elevaalcuadrado\n",
        "{\n",
        "  __device__ float operator()(float x){\n",
        "      return x*x;      \n",
        "  }    \n",
        "}; \n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4);\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  using namespace thrust::placeholders;\n",
        "\n",
        "  // vamos a normalizar un vector por su norma\n",
        "\n",
        "  thrust::device_vector<float> xx(4);\n",
        "  thrust::transform(x.begin(), x.end(),xx.begin(),elevaalcuadrado());\n",
        "  float norma = sqrt(thrust::reduce(xx.begin(),xx.end()));\n",
        "  thrust::transform(x.begin(), x.end(), x.begin(),_1/norma);\n",
        " \n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << x[i] << std::endl;\n",
        "\n",
        "  // deberia dar esto:\n",
        "  // for i in 2. 4. 3. 1.; do echo \"$i/sqrt(2*2+4*4+3*3+1*1)\" | bc -l; done\n",
        "  /*    .36514837167011074230\n",
        "        .73029674334022148461\n",
        "        .54772255750516611345\n",
        "        .18257418583505537115\n",
        "  */\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.365148\n",
            "0.730297\n",
            "0.547723\n",
            "0.182574\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxj3fcOuyHyG"
      },
      "source": [
        "Lo anterior es ineficiente porque usa un vector auxiliar xx, y llama a tres kernels. Usando kernel-fusion se pueden usar solo dos kernels y evitar xx: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_QvCXl2w_PU",
        "outputId": "a3d788f0-bf05-4ff5-90b2-c61a80a99569"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/transform_reduce.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <cmath>\n",
        "\n",
        "struct elevaalcuadrado\n",
        "{\n",
        "  __device__ float operator()(float x){\n",
        "      return x*x;      \n",
        "  }    \n",
        "}; \n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4);\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  using namespace thrust::placeholders;\n",
        "\n",
        "  // vamos a normalizar un vector por su norma\n",
        "\n",
        "  float norma = sqrt( thrust::transform_reduce(\n",
        "      x.begin(), x.end(),\n",
        "      elevaalcuadrado(),\n",
        "      0,thrust::plus<float>()) ); \n",
        "  \n",
        "  thrust::transform(x.begin(), x.end(), x.begin(),_1/norma);\n",
        " \n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << x[i] << std::endl;\n",
        "\n",
        "  // deberia dar esto:\n",
        "  // for i in 2. 4. 3. 1.; do echo \"$i/sqrt(2*2+4*4+3*3+1*1)\" | bc -l; done\n",
        "  /*    .36514837167011074230\n",
        "        .73029674334022148461\n",
        "        .54772255750516611345\n",
        "        .18257418583505537115\n",
        "  */\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.365148\n",
            "0.730297\n",
            "0.547723\n",
            "0.182574\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5V_Sf-uy892"
      },
      "source": [
        "# Portabilidad de Thrust! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWNeSZCjzJ6z"
      },
      "source": [
        "1 código, tres ejecutables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ee4ymIp1zGGn",
        "outputId": "b8ddfd63-fc19-4fe0-b5c0-3cbeb9358b71"
      },
      "source": [
        "%%cuda --name portable.cu\n",
        "\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/transform_reduce.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <cmath>\n",
        "#include <iostream>\n",
        "\n",
        "struct elevaalcuadrado\n",
        "{\n",
        "  __device__ float operator()(float x){\n",
        "      return x*x;      \n",
        "  }    \n",
        "}; \n",
        "\n",
        "int main()\n",
        "{\n",
        "  thrust::device_vector<float> x(4);\n",
        "  x[0] = 2;\n",
        "  x[1] = 4;\n",
        "  x[2] = 3;\n",
        "  x[3] = 1;\n",
        "\n",
        "  using namespace thrust::placeholders;\n",
        "\n",
        "  // vamos a normalizar un vector por su norma\n",
        "\n",
        "  float norma = sqrt( thrust::transform_reduce(\n",
        "      x.begin(), x.end(),\n",
        "      elevaalcuadrado(),\n",
        "      0,thrust::plus<float>()) ); \n",
        "  \n",
        "  thrust::transform(x.begin(), x.end(), x.begin(),_1/norma);\n",
        " \n",
        "  for(int i=0;i<4;i++)\n",
        "  std::cout << x[i] << std::endl;\n",
        "\n",
        "  // deberia dar esto:\n",
        "  // for i in 2. 4. 3. 1.; do echo \"$i/sqrt(2*2+4*4+3*3+1*1)\" | bc -l; done\n",
        "  /*    .36514837167011074230\n",
        "        .73029674334022148461\n",
        "        .54772255750516611345\n",
        "        .18257418583505537115\n",
        "  */\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/portable.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hncUNeYN1i-k"
      },
      "source": [
        "Compilemos el codigo para que corra en GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6bPgn2bzw3f"
      },
      "source": [
        "!nvcc -O2  /content/src/portable.cu -o corroenGPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32iBXDmCz253",
        "outputId": "74f59813-15e8-440a-ad33-39bf563a67ac"
      },
      "source": [
        "!/content/corroenGPU"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.365148\n",
            "0.730297\n",
            "0.547723\n",
            "0.182574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjXOgYlE1nWO"
      },
      "source": [
        "Ahora compilemos el *mismo* codigo pero que corra en CPU en forma serial. Para eso primero le cambiamos la extension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7q0HBiiz7Tn"
      },
      "source": [
        "!cp /content/src/portable.cu /content/src/portable.cpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXiYa-MS1zkO"
      },
      "source": [
        "y ahora lo compilamos con otro compilador, el usual para c++, el que seguro tienen en sus maquinas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_axlIsey0J-j"
      },
      "source": [
        "!g++ -O2 /content/src/portable.cpp -I/usr/local/cuda/include/ -DTHRUST_DEVICE_SYSTEM=THRUST_DEVICE_SYSTEM_CPP -o corroenCPUserial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8lzlplD0Vyw",
        "outputId": "5cd980f2-f1b3-432e-f21a-c5efdc39ea43"
      },
      "source": [
        "!/content/corroenCPUserial"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.365148\n",
            "0.730297\n",
            "0.547723\n",
            "0.182574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErYjdAUY18fL"
      },
      "source": [
        "y finalmente, recompilemos el *mismo* código, pero para que aproveche las CPU multicore, es decir que los algoritmos corran en paralelo en CPU!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NcfsrOt0uo4"
      },
      "source": [
        "!g++ -O2 /content/src/portable.cpp -fopenmp -DTHRUST_DEVICE_SYSTEM=THRUST_DEVICE_SYSTEM_OMP -lgomp -I/usr/local/cuda/include/ -o corroenCPUparalelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx3uxCT_1W6U",
        "outputId": "2d80bf14-62cd-483f-ebef-7ba072dfcf51"
      },
      "source": [
        "!/content/corroenCPUparalelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.365148\n",
            "0.730297\n",
            "0.547723\n",
            "0.182574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAWyvPxk2O_V"
      },
      "source": [
        "Queda como ejercicio correr algo que tenga mucho mas computo y comparar las performances de cada código... ¿qué esperan?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Otros algoritmos y kernel fusion\n"
      ],
      "metadata": {
        "id": "7sDXXp2UYMbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente ejemplo muestra como generar numeros random en host, o como ordenarlos en device, todo usando thrust. El programa es entonces portable."
      ],
      "metadata": {
        "id": "Q2oXG7lmjciL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ordenar en device un vector random generado en host\n",
        "%%cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/sort.h>\n",
        "#include <thrust/copy.h>\n",
        "#include <thrust/random.h>\n",
        "\n",
        "int main() {\n",
        "  // Generate 32M random numbers serially.\n",
        "  thrust::default_random_engine rng(1337);\n",
        "  thrust::uniform_int_distribution<int> dist;\n",
        "  thrust::host_vector<int> h_vec(32 << 20);\n",
        "  thrust::generate(h_vec.begin(), h_vec.end(), [&] { return dist(rng); });\n",
        "\n",
        "  // Transfer data to the device.\n",
        "  thrust::device_vector<int> d_vec = h_vec;\n",
        "\n",
        "  // Sort data on the device.\n",
        "  thrust::sort(d_vec.begin(), d_vec.end());\n",
        "\n",
        "  // Transfer data back to host.\n",
        "  thrust::copy(d_vec.begin(), d_vec.end(), h_vec.begin());\n",
        "\n",
        "  for(int i=0;i<10;i++)\n",
        "  std::cout << h_vec[i] << \" \";\n",
        "  std::cout << std::endl;\n",
        "}"
      ],
      "metadata": {
        "id": "GH_TuzaT31PI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f5e281-da38-4bac-a9e4-6d679be61bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23 88 106 108 110 196 363 576 693 768 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cualculemos ahora la media \n",
        "\n",
        "$$\\langle x \\rangle = \\sum_i x_i/N$$\n",
        "\n",
        "y varianza \n",
        "\n",
        "$$\\langle (x-\\langle x \\rangle)^2 \\rangle = \\sum_i (x_i-\\langle x \\rangle)^2/N$$\n",
        "\n",
        "$$\\langle (x-\\langle x \\rangle)^2 \\rangle = \\langle x^2 \\rangle - \\langle x \\rangle^2$$\n",
        "\n",
        "de un vector muy grande, de $N$ elementos. \n"
      ],
      "metadata": {
        "id": "lJuqjIqxjo4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title media y varianza de numeros random (simple)\n",
        "%%cu \n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/random.h>\n",
        "#include <chrono>\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Generate random data serially.\n",
        "  thrust::default_random_engine rng(133);\n",
        "  thrust::uniform_real_distribution<double> dist(-50.0, 50.0);\n",
        "  thrust::host_vector<double> h_vec(32 << 20);\n",
        "  thrust::generate(h_vec.begin(), h_vec.end(), [&] { return dist(rng); });\n",
        "\n",
        "  // Transfer to device and compute the sum.\n",
        "  thrust::device_vector<double> d_vec = h_vec;\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  double media = thrust::reduce(d_vec.begin(), d_vec.end(), double(0), thrust::plus<double>())/double(32<<20);\n",
        "\n",
        "  using namespace thrust::placeholders;\n",
        "  double var = thrust::transform_reduce(d_vec.begin(), d_vec.end(), (_1-media)*(_1-media), double(0), thrust::plus<double>())/double(32<<20);\n",
        "\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "  auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();\n",
        "\n",
        "\n",
        "  std::cout << \"el promedio da = \" <<  media << std::endl;  \n",
        "  std::cout << \"la varianza da = \" <<  var << std::endl;\n",
        "  std::cout << \"Time elapsed: \" << duration << \" microseconds\" << std::endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkEQMxcZgSd",
        "outputId": "21772258-e164-41eb-e90b-418940bb9403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el promedio da = -0.00730641\n",
            "la varianza da = 833.438\n",
            "Time elapsed: 4293 microseconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(32<<20)\n",
        "print(2<<20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Izk5_sJy4W9",
        "outputId": "a101f458-39c6-4298-cd62-7d3f5eae9ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33554432\n",
            "2097152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el siguiente ejemplo intentaremos optimizar el programa fusionando las dos reducciones (media, varianza)."
      ],
      "metadata": {
        "id": "Ezg4pwirjPuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title media y varianza de numeros random (kernel fussion)\n",
        "%%writefile mediayvar.cu\n",
        "\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/tuple.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <thrust/random.h>\n",
        "#include <chrono>\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Generate random data serially.\n",
        "  thrust::default_random_engine rng(133);\n",
        "  thrust::uniform_real_distribution<double> dist(-50, 50.0);\n",
        "  thrust::host_vector<double> h_vec(32 << 20);\n",
        "  thrust::generate(h_vec.begin(), h_vec.end(), [&] { return dist(rng); });\n",
        "\n",
        "  // Transfer to device and compute the sum.\n",
        "  thrust::device_vector<double> d_vec = h_vec;\n",
        "\n",
        "  auto start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "  auto ambas = \n",
        "  thrust::transform_reduce\n",
        "  (\n",
        "      d_vec.begin(), d_vec.end(), \n",
        "      [=] __device__ (double x)\n",
        "      {\n",
        "          return thrust::make_tuple(x,x*x);          \n",
        "      },\n",
        "      thrust::make_tuple(0.,0.), \n",
        "      [=] __device__ (auto b, auto a){\n",
        "          return \n",
        "          thrust::make_tuple(\n",
        "            thrust::get<0>(a)+thrust::get<0>(b),\n",
        "            thrust::get<1>(a)+thrust::get<1>(b)\n",
        "          );          \n",
        "      }     \n",
        "  );\n",
        "\n",
        "  auto end = std::chrono::high_resolution_clock::now();\n",
        "  auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start).count();\n",
        "\n",
        "  double media= thrust::get<0>(ambas)/double(32<<20);\n",
        "  double var= thrust::get<1>(ambas)/double(32<<20)-media*media;\n",
        "\n",
        "  std::cout << \"el promedio da = \" <<  media << std::endl;  \n",
        "  std::cout << \"la varianza da = \" <<  var << std::endl;\n",
        "  std::cout << \"Time elapsed: \" << duration << \" microseconds\" << std::endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7S8EV9haguC",
        "outputId": "3e332898-8910-4158-d20d-21d005449e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mediayvar.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --extended-lambda mediayvar.cu ; ./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr-5hQQhd0Ba",
        "outputId": "d0b95771-5974-42de-aeba-2f047544fd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el promedio da = -0.00730641\n",
            "la varianza da = 833.438\n",
            "Time elapsed: 2095 microseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foWhfqPqeI6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}